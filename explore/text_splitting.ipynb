{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing \n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# embeddings + text\n",
    "from langchain_core import documents\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import GigaChatEmbeddings\n",
    "\n",
    "# neo4j\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.graphs import Neo4jGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neo4j:\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE= os.getenv('NEO4J_DATABASE')\n",
    "\n",
    "# llm:\n",
    "LLM_SCOPE = os.getenv('SCOPE')\n",
    "LLM_AUTH = os.getenv('AUTH_DATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./закупка.txt\"\n",
    "\n",
    "loader = TextLoader(path, encoding = 'UTF-8')\n",
    "text_documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextSplitter:\n",
    "    def __init__(self, target_chunk_size=1000):\n",
    "        \n",
    "        self.target_chunk_size = target_chunk_size\n",
    "        self.source = ''\n",
    "        self.chunks = []\n",
    "        self.current_chunk = ''\n",
    "        self.dcts = []\n",
    "        self.bullet_name = ''\n",
    "        self.prev_bullet_name = ''\n",
    "        self.mode_list = ['bullet', 'line', 'space']\n",
    "        self.sep_dict = {'line': '\\n', 'space': ' '}\n",
    "        self.link_dict = {'bullet': '\\n', 'line': '\\n', 'space': ' '}\n",
    "        \n",
    "    def is_bullet(self, line):\n",
    "        # Проверка, начинается ли строка с буллита\n",
    "        return re.match(r'(\\d+(\\.\\d+)*\\.\\d+)\\.? ', line.strip())\n",
    "    \n",
    "    def make_chunks(self, input_text, mode):\n",
    "        link = self.link_dict[mode] \n",
    "        if len(input_text) == 0:\n",
    "            return\n",
    "        if len(self.current_chunk) > 0:\n",
    "            # Если текущий чанк не пуст, проверяем, поместится ли туда текущий фрагмент\n",
    "            new_chunk = self.current_chunk + link + input_text\n",
    "            if len(new_chunk) <= self.target_chunk_size and mode != 'bullet':\n",
    "                    self.current_chunk = new_chunk\n",
    "            else:\n",
    "                # Сначала сохраняем текущий чанк, потом \n",
    "                # в текущий чанк записываем новый фрагмент\n",
    "                self.chunks.append(self.current_chunk)\n",
    "                dct = documents.base.Document(self.current_chunk)\n",
    "                dct.metadata = {'source': self.source}\n",
    "                # Записываем имя буллита чанка в метаданные\n",
    "                if mode == 'bullet':\n",
    "                    dct.metadata['bullet'] = self.prev_bullet_name\n",
    "                else:\n",
    "                    dct.metadata['bullet'] = self.bullet_name\n",
    "                self.dcts.append(dct)\n",
    "                self.current_chunk = ''\n",
    "                if len(input_text) <= self.target_chunk_size:\n",
    "                    self.current_chunk = input_text\n",
    "                else:\n",
    "                    # Текст не помещается в чанк целиком. Тогда определяем параметры нового \n",
    "                    # разбиения и вызываем рекурсивно этот же метод.\n",
    "                    next_mode, separator = self.prepare_for_new_split(mode)\n",
    "                    if next_mode is None:\n",
    "                        return\n",
    "                    else:\n",
    "                        for item in input_text.split(separator):\n",
    "                            self.make_chunks(item, next_mode)\n",
    "                        # После завершения разбиения сохраняем текущий чанк, если он не пуст.    \n",
    "                        if self.current_chunk != '':\n",
    "                            self.chunks.append(self.current_chunk)\n",
    "                            dct = documents.base.Document(self.current_chunk)\n",
    "                            # В текущей реализации в метаданные пишется имя последнего буллита чанка\n",
    "                            dct.metadata = {'source': self.source,'bullet': self.bullet_name}\n",
    "                            self.dcts.append(dct)\n",
    "                            self.current_chunk = ''\n",
    "        elif len(input_text) <= self.target_chunk_size:\n",
    "                self.current_chunk = input_text\n",
    "        else:\n",
    "            # Текст не помещается в чанк целиком. Тогда определяем параметры нового \n",
    "            # разбиения и вызываем рекурсивно этот же метод.            \n",
    "            next_mode, separator = self.prepare_for_new_split(mode)\n",
    "            if next_mode is None:\n",
    "                return\n",
    "            else:\n",
    "                for item in input_text.split(separator):\n",
    "                    self.make_chunks(item, next_mode)\n",
    "                # После завершения разбиения сохраняем текущий чанк, если он не пуст. \n",
    "                if self.current_chunk != '':\n",
    "                    self.chunks.append(self.current_chunk)\n",
    "                    dct = documents.base.Document(self.current_chunk)\n",
    "                    # Записываем имя буллита чанка в метаданные\n",
    "                    dct.metadata = {'source': self.source,'bullet': self.bullet_name}\n",
    "                    self.dcts.append(dct)\n",
    "                    self.current_chunk = ''\n",
    "    \n",
    "    def prepare_for_new_split(self, current_mode):\n",
    "        # Определяем параметры разбиения\n",
    "            next_mode_index = self.mode_list.index(current_mode) + 1\n",
    "            if next_mode_index < len(self.mode_list):\n",
    "                next_mode = self.mode_list[next_mode_index]\n",
    "                next_separator = self.sep_dict[next_mode]\n",
    "                return next_mode, next_separator\n",
    "            else:\n",
    "                return None, None\n",
    "            \n",
    "    def split_text(self, text, source):\n",
    "        bullet_chunks = []\n",
    "        current_bullet_chunk = ''\n",
    "        self.source = source\n",
    "        # Разбиваем исходный текст на куски, каждый из которых (кроме первого) \n",
    "        # начинается с буллита\n",
    "        lines = text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if len(line) > 0:\n",
    "                if self.is_bullet(line):\n",
    "                    if len(current_bullet_chunk) > 0:\n",
    "                        bullet_chunks.append(current_bullet_chunk)\n",
    "                    current_bullet_chunk = line      \n",
    "                elif len(current_bullet_chunk) > 0:\n",
    "                    current_bullet_chunk = current_bullet_chunk + '\\n' + line\n",
    "                else:\n",
    "                    current_bullet_chunk = line     \n",
    "        bullet_chunks.append(current_bullet_chunk)\n",
    "        # Для каждого буллита сохраняем его имя (=номер) и вызываем метод разбивки на чанки\n",
    "        for bc in bullet_chunks:\n",
    "            if len(bc) > 0:\n",
    "                self.prev_bullet_name = self.bullet_name\n",
    "                if self.is_bullet(bc):\n",
    "                    self.bullet_name = self.is_bullet(bc).group()\n",
    "                else:\n",
    "                    self.bullet_name = bc.split()[0]\n",
    "                self.make_chunks(bc, 'bullet')\n",
    "                \n",
    "        return self.dcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Стандарт на процесс Проведение закупки у единственног о поставщика (подрядчика, исполнителя) Содержание 1 Область применения 3 2 Нормативные ссылки 4 3 Термины и сокращения 4 4 Основания для проведения закупки у единственного поставщика (подрядчика, исполнителя) 7 5 Назначение и структура процесса 10 6 Порядок выполнения подпроцесса 03.03.02.01.01 «Закупка у ЕдП (НМЦ менее 10 млн руб. без НДС)» 14 7 Порядок выполнения подпроцесса 03.03.02.01.02 «Закупка у ЕдП (НМЦ 10 млн руб. без НДС и более)» 21 Приложение 1 Описание комплектов документов 31 Приложение 2 Особенности организации закупки у единственного поставщика (подрядчика, исполнителя) по отдельным основаниям Положения о закупках ПАО Компания 1» (обязательное) 32 Библиография 35 История изменений документа 36 Шаблоны, введенные в действие настоящим документом (обеспечивающие выполнение документа) 1 Область применения', metadata={'source': './закупка.txt', 'bullet': 'Стандарт'}),\n",
       " Document(page_content='1.1 Настоящий стандарт устанавливает единые правила и порядок проведения закупок товаров, работ, услуг у единственного поставщика (подрядчика, исполнителя), относится к группе процессов 03.03 «Выбор контрагентов для поставки товаров, выполнения работ, оказания услуг» категории 03 «Управление закупками».', metadata={'source': './закупка.txt', 'bullet': '1.1 '}),\n",
       " Document(page_content='1.2 При распространении НМД через механизм тиражирование:', metadata={'source': './закупка.txt', 'bullet': '1.2 '}),\n",
       " Document(page_content='1.2.1 Положения настоящего стандарта вступают в силу с момента его утверждения и действуют до момента утверждения актуализированной версии стандарта.', metadata={'source': './закупка.txt', 'bullet': '1.2.1 '}),\n",
       " Document(page_content='1.2.2 Положения стандарта подлежат соблюдению в ПАО «Компания 1» и Обществах Компания 1, утвердивших собственный аналогичный стандарт.', metadata={'source': './закупка.txt', 'bullet': '1.2.2 '})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разбиение текста на чанки. Лимит чанка по умолчанию =1000. Если нужен другой, \n",
    "# задаём его с помощью target_chunk_size=... при создании splitter\n",
    "\n",
    "splitter = CustomTextSplitter()\n",
    "test_chunks = splitter.split_text(text_documents[0].page_content, text_documents[0].metadata['source'])\n",
    "test_chunks[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4j "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Nodes with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GigaChatEmbeddings(credentials=LLM_AUTH, verify_ssl_certs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neo4j_vector = Neo4jVector.from_documents(\n",
    "#     test_chunks, # documents\n",
    "#     embeddings,\n",
    "#     url = NEO4J_URI,\n",
    "#     username = NEO4J_USERNAME,\n",
    "#     password = NEO4J_PASSWORD\n",
    "#     # index_name = \"vector\",  # 'vector' by default\n",
    "#     # node_label = \"Chunk\",  # 'Chunk' by default\n",
    "#     # text_node_property = \"content\",  # 'text' by default\n",
    "#     # embedding_node_property = \"vector\",  # 'embedding' by default\n",
    "#     # create_id_index = True,  # 'True' by default\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neo4j_vector = Neo4jVector.from_documents(\n",
    "#     test_chunks, # documents\n",
    "#     embeddings,\n",
    "#     url = NEO4J_URI,\n",
    "#     username = NEO4J_USERNAME,\n",
    "#     password = NEO4J_PASSWORD, \n",
    "#     search_type=\"hybrid\",\n",
    "#     index_name=\"Document\",  # vector by default\n",
    "#     node_label=\"Document\"  # Chunk by default\n",
    "#     # text_node_property=\"content\",  # text by default\n",
    "#     # embedding_node_property=\"vector\",  # embedding by default\n",
    "#     # create_id_index=True,  # True by default\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Add documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4jVector.add_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Existing Nodes / Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_vector = Neo4jVector.from_existing_index(\n",
    "    embeddings,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=\"vector\", \n",
    "    node_label = \"Chunk\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector\n",
      "Chunk\n",
      "embedding\n"
     ]
    }
   ],
   "source": [
    "print(neo4j_vector.index_name)\n",
    "print(neo4j_vector.node_label)\n",
    "print(neo4j_vector.embedding_node_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_vector_hybrid = Neo4jVector.from_existing_index(\n",
    "    embeddings,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    search_type=\"hybrid\",\n",
    "    keyword_index_name = \"keyword\",\n",
    "    index_name=\"Document\",  # vector by default\n",
    "    node_label=\"Document\"  # Chunk by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document\n",
      "keyword\n",
      "Document\n",
      "embedding\n"
     ]
    }
   ],
   "source": [
    "print(neo4j_vector_hybrid.index_name)\n",
    "print(neo4j_vector_hybrid.keyword_index_name)\n",
    "print(neo4j_vector_hybrid.node_label)\n",
    "print(neo4j_vector_hybrid.embedding_node_property)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties are the following:\n",
      "Chunk {embedding: LIST, id: STRING, text: STRING, source: STRING, bullet: STRING}\n",
      "Relationship properties are the following:\n",
      "\n",
      "The relationships are the following:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 8,\n",
       "  'name': 'vector',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'VECTOR',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Chunk'],\n",
       "  'properties': ['embedding'],\n",
       "  'indexProvider': 'vector-2.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': neo4j.time.DateTime(2024, 4, 17, 21, 4, 49, 896000000, tzinfo=<UTC>),\n",
       "  'readCount': 8}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher = \"\"\"\n",
    "  SHOW VECTOR INDEXES\n",
    "  \"\"\"\n",
    "graph.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count(n)': 1157}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (n)\n",
    "  RETURN count(n)\n",
    "  \"\"\"\n",
    "graph.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '1.2. При распространении НМД через механизм тиражирование:\\n1.2.1.Положения настоящего стандарта вступают в силу с момента его утверждения и действуют до момента утверждения актуализированной версии стандарта.'},\n",
       " {'text': '1.2. Термины и определения'},\n",
       " {'text': '1.2. При распространении НМД через механизм тиражирование:'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher = \"\"\"\n",
    "    MATCH (n:Chunk {bullet: \"1.2\"})\n",
    "    RETURN n.text AS text\n",
    "    \"\"\"\n",
    "graph.query(cypher)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
